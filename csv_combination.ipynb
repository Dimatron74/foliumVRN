{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1739793461975,
     "user": {
      "displayName": "Dimatron",
      "userId": "17867600572042528780"
     },
     "user_tz": -180
    },
    "id": "tRIxEZfDQPlL"
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    \"\"\"Функция для определения кодировки файла.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "    result = chardet.detect(raw_data)\n",
    "    return result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166778,
     "status": "ok",
     "timestamp": 1739796753684,
     "user": {
      "displayName": "Dimatron",
      "userId": "17867600572042528780"
     },
     "user_tz": -180
    },
    "id": "FSDRAhHpshML",
    "outputId": "9f5c9656-c8be-497c-d600-0a6e5a9e6626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Доступные столбцы в файле 'csv\\Popularity2020.csv': ['total_population_2020', 'male_population', 'female_population', 'male_percent', 'female_percent']\n",
      "\n",
      "Доступные столбцы в файле 'csv\\Popularity2010.csv': ['total_population_2010', 'male_population', 'female_population', 'male_percent', 'female_percent']\n",
      "Комбинированная таблица успешно сохранена в файл: combined_table.csv\n"
     ]
    }
   ],
   "source": [
    "# !pip install fuzzywuzzy # Требуется для Google Colab\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Функция для нормализации названий регионов\n",
    "def normalize_region_name(name):\n",
    "    if not name or not isinstance(name, str):  # Игнорируем пустые или некорректные значения\n",
    "        return None\n",
    "    name = name.lower() \\\n",
    "        .replace('городской округ', 'округ') \\\n",
    "        .replace('муниципальный район', 'район') \\\n",
    "        .replace('сельское население', '') \\\n",
    "        .replace('городское население', '') \\\n",
    "        .replace('сельское поселение', 'поселение') \\\n",
    "        .replace('-', '').replace('ё', 'е').strip()\n",
    "    # Убираем лишние пробелы, но оставляем ключевые слова\n",
    "    return ' '.join(e for e in name.split() if e.isalnum() or e in ['г.', 'округ', 'район', 'поселение'])\n",
    "\n",
    "# Улучшенная функция для поиска наиболее подходящего совпадения\n",
    "def find_matching_region(target, candidates):\n",
    "    # Проверка на точное совпадение\n",
    "    if target in candidates:\n",
    "        return target\n",
    "    # Проверка на частичное совпадение\n",
    "    for candidate in candidates:\n",
    "        if target in candidate or candidate in target:\n",
    "            return candidate\n",
    "    # Если ничего не найдено, используем fuzzywuzzy (в крайних случаях)\n",
    "    max_similarity = 0\n",
    "    best_match = None\n",
    "    for candidate in candidates:\n",
    "        similarity = fuzz.token_set_ratio(target, candidate)\n",
    "        if similarity > 85 and similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_match = candidate\n",
    "    return best_match\n",
    "\n",
    "# Функция для фильтрации данных по указанной области\n",
    "def filter_data_by_region(data, target_region):\n",
    "    filtered_data = []\n",
    "    collecting = False\n",
    "    for _, row in data.iterrows():\n",
    "        region = row['region'].lower()\n",
    "        if region == target_region.lower():  # Начинаем собирать данные при нахождении целевой области\n",
    "            collecting = True\n",
    "            continue\n",
    "        if collecting:\n",
    "            if region.endswith('область') or region.endswith('край'):  # Берём только районы и городские округа\n",
    "                break\n",
    "            else:\n",
    "                if normalize_region_name(region):\n",
    "                    filtered_data.append(row.to_dict())\n",
    "    return pd.DataFrame(filtered_data).set_index('region')\n",
    "\n",
    "# Загрузка CSV-файлов от пользователя\n",
    "csv_files = []\n",
    "while True:\n",
    "    file_path = input(\"Введите путь к CSV файлу (или оставьте пустым для завершения): \").strip()\n",
    "    if not file_path:\n",
    "        break\n",
    "    csv_files.append(file_path)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"Нет загруженных файлов. Программа завершена.\")\n",
    "    exit()\n",
    "\n",
    "# Чтение данных из всех CSV-файлов\n",
    "data_frames = []\n",
    "russian_headers = []  # Список для хранения русских заголовков\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        encoding = detect_encoding(file)\n",
    "        # Читаем первую строку как английские заголовки\n",
    "        df = pd.read_csv(file, sep=';', encoding=encoding, header=0)\n",
    "        df.columns = [col.strip().lower() for col in df.columns]  # Приводим названия столбцов к нижнему регистру\n",
    "\n",
    "        # Читаем вторую строку как русские заголовки\n",
    "        with open(file, 'r', encoding=encoding) as f:\n",
    "            next(f)  # Пропускаем первую строку (английские заголовки)\n",
    "            russian_header = next(f).strip().split(';')  # Читаем вторую строку (русские заголовки)\n",
    "            russian_headers.append([col.strip() for col in russian_header])  # Сохраняем русские заголовки\n",
    "\n",
    "        df['region'] = df['region'].str.strip().str.lower()  # Нормализуем столбец region\n",
    "        df = df.dropna(subset=['region'])  # Удаляем строки с пустыми регионами\n",
    "        data_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла {file}: {e}\")\n",
    "\n",
    "if not data_frames:\n",
    "    print(\"Не удалось загрузить данные из файлов. Программа завершена.\")\n",
    "    exit()\n",
    "\n",
    "# Пользователь выбирает область для фильтрации\n",
    "target_region = input(\"Введите название области для фильтрации (например, 'воронежская область'): \").strip().lower()\n",
    "\n",
    "# Фильтрация данных по выбранной области\n",
    "filtered_data = []\n",
    "for df in data_frames:\n",
    "    filtered_df = filter_data_by_region(df, target_region)\n",
    "    if not filtered_df.empty:\n",
    "        filtered_data.append(filtered_df)\n",
    "\n",
    "if not filtered_data:\n",
    "    print(\"Данные для указанной области не найдены. Программа завершена.\")\n",
    "    exit()\n",
    "\n",
    "# Функция для выбора столбцов пользователем\n",
    "def select_columns(df, file_name):\n",
    "    print(f\"\\nДоступные столбцы в файле '{file_name}': {df.columns.tolist()}\")\n",
    "    selected_columns = input(\"Введите через запятую названия столбцов, которые хотите добавить: \").strip()\n",
    "    if not selected_columns:\n",
    "        return []\n",
    "    return [col.strip().lower() for col in selected_columns.split(\",\")]  # Приводим к нижнему регистру\n",
    "\n",
    "# Создание комбинированной таблицы\n",
    "combined_data = []\n",
    "\n",
    "# Выбор столбцов для каждого файла\n",
    "selected_columns_per_file = []\n",
    "for j, df in enumerate(filtered_data):\n",
    "    selected_columns = select_columns(df, csv_files[j])\n",
    "    selected_columns_per_file.append(selected_columns)\n",
    "\n",
    "# Список всех уникальных регионов из всех таблиц\n",
    "all_regions = set()\n",
    "for df in filtered_data:\n",
    "    all_regions.update(df.index.map(normalize_region_name))\n",
    "\n",
    "# Подсчёт количества вхождений каждого имени столбца\n",
    "column_counts = {}\n",
    "for selected_columns in selected_columns_per_file:\n",
    "    for col in selected_columns:\n",
    "        column_counts[col] = column_counts.get(col, 0) + 1\n",
    "\n",
    "# Список всех выбранных столбцов с уникальными именами\n",
    "all_unique_columns = ['region']  # 'region' всегда добавляется как первый столбец\n",
    "column_names_tracker = {}  # Словарь для отслеживания уникальных названий столбцов\n",
    "russian_column_names = {}  # Словарь для хранения русских названий столбцов\n",
    "\n",
    "# Генерация уникальных имен для выбранных столбцов\n",
    "for j, selected_columns in enumerate(selected_columns_per_file):\n",
    "    for col in selected_columns:\n",
    "        original_name = col\n",
    "        if column_counts[original_name] > 1:  # Если столбец встречается более одного раза\n",
    "            unique_name = f\"{original_name}_{j}\"  # Добавляем суффикс с индексом файла\n",
    "        else:\n",
    "            unique_name = original_name  # Оставляем имя без суффикса\n",
    "        all_unique_columns.append(unique_name)\n",
    "        column_names_tracker[(original_name, j)] = unique_name\n",
    "\n",
    "        # Сохраняем русское название столбца\n",
    "        english_headers = [col.strip().lower() for col in data_frames[j].columns]\n",
    "        russian_index = english_headers.index(original_name)\n",
    "        russian_name = russian_headers[j][russian_index]\n",
    "        russian_column_names[unique_name] = russian_name\n",
    "\n",
    "# Функция для очистки числовых данных от пробелов\n",
    "def clean_numeric_value(value):\n",
    "    if isinstance(value, str):  # Если значение — строка\n",
    "        value = value.replace(' ', '')  # Убираем пробелы\n",
    "        try:\n",
    "            # Попытка преобразовать строку в число (целое или с плавающей точкой)\n",
    "            if '.' in value:\n",
    "                return float(value)\n",
    "            else:\n",
    "                return int(value)\n",
    "        except ValueError:\n",
    "            pass  # Если преобразование не удалось, оставляем строку как есть\n",
    "    return value\n",
    "\n",
    "# Обработка всех регионов\n",
    "for region in all_regions:\n",
    "    combined_row = {'region': region}\n",
    "    for j, df in enumerate(filtered_data):\n",
    "        # Нормализация индексов текущего DataFrame\n",
    "        df.index = df.index.map(normalize_region_name)\n",
    "        # Поиск совпадения\n",
    "        match = find_matching_region(region, df.index.tolist())\n",
    "        if match and match in df.index:\n",
    "            match_index = df.index.tolist().index(match)\n",
    "            # Добавляем выбранные столбцы\n",
    "            for col in selected_columns_per_file[j]:\n",
    "                original_name = col\n",
    "                unique_name = column_names_tracker[(original_name, j)]\n",
    "                if col in df.columns:\n",
    "                    value = df.iloc[match_index][col]\n",
    "                    combined_row[unique_name] = clean_numeric_value(value)  # Очистка числовых данных\n",
    "        else:\n",
    "            # Если совпадения нет, добавляем пустые значения\n",
    "            for col in selected_columns_per_file[j]:\n",
    "                original_name = col\n",
    "                unique_name = column_names_tracker[(original_name, j)]\n",
    "                combined_row[unique_name] = None\n",
    "    combined_data.append(combined_row)\n",
    "\n",
    "# Преобразование списка словарей в DataFrame\n",
    "combined_data_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Создание DataFrame для русских названий столбцов\n",
    "russian_names_row = {col: russian_column_names.get(col, \"\") for col in all_unique_columns}\n",
    "\n",
    "# Для region берём русское название из первой таблицы\n",
    "russian_names_row['region'] = russian_headers[0][0]\n",
    "\n",
    "# Добавление русских названий в комбинированную таблицу\n",
    "combined_data_df = pd.concat([pd.DataFrame([russian_names_row]), combined_data_df])\n",
    "\n",
    "# Убедимся, что region остается первым столбцом\n",
    "combined_data_df = combined_data_df[all_unique_columns]\n",
    "\n",
    "# Сохранение комбинированной таблицы в CSV\n",
    "output_file = input(\"Введите путь для сохранения комбинированной таблицы (например, 'combined_table.csv'): \").strip()\n",
    "if not output_file:\n",
    "    output_file = 'combined_table.csv'\n",
    "try:\n",
    "    combined_data_df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)  # Убираем индекс Pandas\n",
    "    print(f\"Комбинированная таблица успешно сохранена в файл: {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении файла: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1cM9du/gA/7C1/OH0vsmQ",
   "mount_file_id": "1XEReLfBBlg6x8zxPqnGDBJziY5Kpkk3_",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
